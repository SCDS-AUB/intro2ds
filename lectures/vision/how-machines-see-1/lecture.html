---
layout: default
title: "How Machines See - Part 1: Traditional Computer Vision"
---

<nav class="breadcrumb">
  <a href="{{ '/' | relative_url }}">Home</a> /
  <a href="{{ '/lectures.html' | relative_url }}">Lectures</a> /
  <a href="{{ '/lectures.html#vision' | relative_url }}">Vision</a> /
  Part 1
</nav>

<article class="lecture-content">
  <header>
    <h1>How Machines See - Part 1</h1>
    <p class="subtitle">Traditional Computer Vision</p>
    <div class="meta">
      <span>Module: Vision</span>
      <span>Course: DATA 201</span>
    </div>
    <div class="resources">
      <a href="lecture.ipynb" class="btn">Download Notebook</a>
      <a href="lecture.md" class="btn btn-secondary">View Markdown</a>
    </div>
  </header>

  <section class="objectives">
    <h2>Learning Objectives</h2>
    <ol>
      <li>Understand digital image representation (pixels, bytes, colors)</li>
      <li>Implement geometric approaches to pattern recognition</li>
      <li>Apply traditional computer vision techniques (edge detection, features)</li>
      <li>Analyze where hand-coded approaches fail</li>
      <li>Develop epistemic humility about model limitations</li>
    </ol>
  </section>

  <section class="content">
    <h2>Today's Question</h2>
    <p><strong>What is seeing for a machine?</strong></p>
    <p>We understand machines seeing more than we understand how we see things. Why? <em>Because we built them.</em></p>

    <h2>Part 1: What Are Images?</h2>
    <p>Before we teach machines to see, we need to understand what images actually are to a computer.</p>

    <h3>Pixels and Grayscale</h3>
    <ul>
      <li>Images are <strong>2D arrays of numbers</strong></li>
      <li>Each pixel stores a brightness value: 0 (black) to 255 (white)</li>
      <li>Why 255? Because $2^8 = 256$ (one byte)</li>
    </ul>

    <h3>Mathematical Representation</h3>
    <p>An image is a function: $I: \mathbb{R}^2 \to \mathbb{R}$</p>
    <p>Discretely: $I[x, y] \in \{0, 1, 2, \ldots, 255\}$</p>

    <h3>Color Images: RGB</h3>
    <p>Three channels stacked: $I[x, y] = (R[x,y], G[x,y], B[x,y])$</p>
    <p>Total colors: $256^3 = 16,777,216$</p>

    <h2>Part 2: Geometric Approaches</h2>
    <p>Can we write rules to detect specific digits?</p>

    <h3>Spike Detector for Digit "1"</h3>
    <p>Sum pixel values along columns:</p>
    <p>$$S[j] = \sum_{i=1}^{H} I[i, j]$$</p>
    <p><strong>Problem:</strong> Hand-coded rules are fragile. Different handwriting breaks them.</p>

    <h3>Edge Detection (Sobel)</h3>
    <p>Kernels for detecting edges:</p>
    <p>$$K_x = \begin{bmatrix} -1 & 0 & 1 \\ -2 & 0 & 2 \\ -1 & 0 & 1 \end{bmatrix}$$</p>
    <p>Edge strength: $G = \sqrt{(I * K_x)^2 + (I * K_y)^2}$</p>

    <h2>Part 3: Classical ML Pipeline</h2>
    <ol>
      <li><strong>Preprocessing</strong>: Normalize, denoise, threshold</li>
      <li><strong>Feature Extraction</strong>: HOG, SIFT, edges</li>
      <li><strong>Classification</strong>: SVM, Random Forest</li>
      <li><strong>Evaluation</strong>: Accuracy, confusion matrix</li>
    </ol>

    <h2>Key Takeaways</h2>
    <ul>
      <li>Images are just numbers (2D arrays of pixel values)</li>
      <li>Hand-coded rules are fragile</li>
      <li>Feature extraction matters</li>
      <li>Classical ML (SVM) achieves ~95%+ accuracy</li>
      <li>Failure analysis is informative</li>
    </ul>

    <blockquote>
      <strong>The Feature Engineering Bottleneck:</strong> Traditional CV requires experts to design features. What if we don't know which features matter?
    </blockquote>
  </section>

  <footer class="lecture-nav">
    <span></span>
    <a href="../how-machines-see-2/lecture.html" class="next">Part 2: Modern ML â†’</a>
  </footer>
</article>

<style>
.breadcrumb { font-size: 0.9rem; color: #666; margin-bottom: 1.5rem; }
.breadcrumb a { color: var(--accent-color); }
.lecture-content header { margin-bottom: 2rem; padding-bottom: 1.5rem; border-bottom: 1px solid var(--border-color); }
.lecture-content h1 { margin-bottom: 0.25rem; }
.subtitle { font-size: 1.3rem; color: #666; margin-bottom: 1rem; }
.meta { font-size: 0.9rem; color: #888; margin-bottom: 1rem; }
.meta span { margin-right: 1.5rem; }
.btn-secondary { background: #e9ecef; color: var(--primary-color); }
.btn-secondary:hover { background: #dee2e6; }
.objectives { background: var(--light-bg); padding: 1.5rem; border-radius: 6px; margin-bottom: 2rem; }
.objectives h2 { margin-top: 0; }
.lecture-nav { display: flex; justify-content: space-between; margin-top: 3rem; padding-top: 1.5rem; border-top: 1px solid var(--border-color); }
</style>
